{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "$id": "https://github.com/pzaino/thecrowler/main/schemas/crowler-source-config-schema.json",
  "title": "CROWler Source Configuration",
  "description": "This is the configuration for a Source (base URL) that the CROWler will use to crawl websites.",
  "version": "1.0.0",
  "type": "object",
  "properties": {
    "version": {
      "title": "CROWler Source Configuration version",
      "description": "This is the version of the CROWler Source configuration, this is for you to version your work.",
      "type": "string",
      "pattern": "^\\d+\\.\\d+\\.\\d+$"
    },
    "format_version": {
      "title": "CROWler Source Configuration Schema version",
      "description": "This is the version of the CROWler Source configuration schema.",
      "type": "string",
      "pattern": "^\\d+\\.\\d+\\.\\d+$",
      "examples": [
        "1.0.0"
      ]
    },
    "author": {
      "title": "CROWler Source Configuration author",
      "description": "This is the author of the CROWler Source configuration.",
      "type": "string"
    },
    "description": {
      "title": "CROWler Source Configuration description",
      "description": "A description field for you to describe why this custom Source configuration.",
      "type": "string"
    },
    "created_at": {
      "title": "CROWler Source Configuration creation date",
      "description": "This is the date when the CROWler Source configuration was created.",
      "type": "string",
      "pattern": "(?:(?:(?:(\\d{4})[-\\/\\.](\\d{2})[-\\/\\.](\\d{2}))|(?:(\\d{2})[-\\/\\.](\\d{2})[-\\/\\.](\\d{4})))\\s*(?:T\\s*)?)?(?:(\\d{1,2}):(\\d{2})(?::(\\d{2}))?\\s*([AaPp][Mm])?)?"
    },
    "source_name": {
      "title": "CROWler Configuration source name",
      "description": "This is the name of the source (URL) that the CROWler will crawl.",
      "type": "string"
    },
    "crawling_config": {
      "type": "object",
      "properties": {
        "site": {
          "type": "string",
          "format": "uri"
        },
        "url_referrer": {
          "type": "string",
          "format": "uri",
          "description": "This is the URL referrer for the source. It is used to set the referrer for the source when crawling."
        },
        "alternative_links": {
          "type": "array",
          "items": {
            "type": "string",
            "format": "uri"
          },
          "description": "This is the list of URLs that the CROWler will use if no links are found on the source. This is useful for sources that have no links or for sources that have links that are not relevant to the source."
        },
        "retries_on_redirect": {
          "type": "integer",
          "minimum": 0,
          "default": 0,
          "description": "This is the number of retries on redirect. Redirects are identified via 'unwanted_urls' patterns. If the CROWler encounters such a redirect, it will retry the original Link this many times before giving up. This can help with certain websites that redirect to different URLs based on the user agent or other factors."
        },
        "unwanted_urls": {
          "type": "array",
          "items": {
            "type": "string",
            "description": "Regex pattern to match unwanted redirect URLs."
          },
          "description": "This is a list of unwanted URLs patterns that the CROWler uses to detect problematic redirects. If a redirect leads to one of these URLs, the CROWler will attempt to reload the original URL instead. This helps avoid irrelevant or error-prone URLs during crawling. It's not a block list, but a way to tell the system, 'retry the original URL if we get redirected here'."
        },
        "source_type": {
          "type": "string",
          "enum": [
            "website",
            "api",
            "file",
            "db"
          ],
          "description": "This is the type of the source. It can be a website, an API or a file."
        },
        "load_validation": {
          "title": "Page Load Validation",
          "description": "Rules that declare a page 'loaded correctly' based on current URL and DOM checks.",
          "type": "object",
          "properties": {
            "groups": {
              "type": "array",
              "minItems": 1,
              "items": {
                "$ref": "#/properties/crawling_config/properties/load_validation/definitions/validationGroup"
              }
            }
          },
          "required": [
            "groups"
          ],
          "additionalProperties": false,
          "definitions": {
            "validationGroup": {
              "type": "object",
              "properties": {
                "url_pattern": {
                  "type": "string",
                  "minLength": 1,
                  "description": "PCRE-style regex applied to the CURRENT URL after navigation."
                },
                "scope": {
                  "type": "string",
                  "enum": [
                    "seed_only",
                    "source_domain",
                    "same_origin",
                    "all_crawled"
                  ],
                  "default": "source_domain"
                },
                "validations": {
                  "type": "array",
                  "minItems": 1,
                  "items": {
                    "$ref": "#/properties/crawling_config/properties/load_validation/definitions/validation"
                  }
                },
                "any_validation_satisfies": {
                  "type": "boolean",
                  "default": true,
                  "description": "If true, the group passes when any validation passes (default)."
                },
                "on_fail": {
                  "type": "string",
                  "enum": [
                    "retry",
                    "mark_invalid",
                    "skip",
                    "log_only"
                  ],
                  "default": "mark_invalid",
                  "description": "Action when no validation passes."
                },
                "max_retries": {
                  "type": "integer",
                  "minimum": 0,
                  "default": 0,
                  "description": "Group-level retries when on_fail=retry."
                }
              },
              "required": [
                "url_pattern",
                "validations"
              ],
              "additionalProperties": false
            },
            "validation": {
              "type": "object",
              "properties": {
                "dom_checks": {
                  "type": "array",
                  "minItems": 1,
                  "items": {
                    "$ref": "#/properties/crawling_config/properties/load_validation/definitions/domCheck"
                  }
                },
                "all_checks_must_pass": {
                  "type": "boolean",
                  "default": true,
                  "description": "AND across checks when true, otherwise OR."
                },
                "on_fail": {
                  "type": "string",
                  "enum": [
                    "retry"
                  ],
                  "description": "If present and set to 'retry', the engine may retry this validation before moving on."
                },
                "max_retries": {
                  "type": "integer",
                  "minimum": 0,
                  "default": 0,
                  "description": "Retries for this validation when on_fail=retry."
                }
              },
              "required": [
                "dom_checks"
              ],
              "additionalProperties": false
            },
            "domCheck": {
              "type": "object",
              "properties": {
                "selector": {
                  "type": "string",
                  "minLength": 1,
                  "description": "CSS selector used to select elements to validate. Mirrors ruleset selectors style."
                },
                "timeout": {
                  "type": "string",
                  "description": "Seconds or ExprTerpreter expression (e.g., 'random(1,3)')."
                },
                "conditions": {
                  "type": "array",
                  "items": {
                    "$ref": "#/properties/crawling_config/properties/load_validation/definitions/domCondition"
                  },
                  "description": "ANY-of conditions over the selected elements. If omitted, defaults to 'exists >= 1' at runtime."
                }
              },
              "required": [
                "selector"
              ],
              "additionalProperties": false
            },
            "domCondition": {
              "type": "object",
              "properties": {
                "type": {
                  "type": "string",
                  "enum": [
                    "exists",
                    "not_exists",
                    "text",
                    "attribute",
                    "count"
                  ]
                },
                "attribute": {
                  "type": "string",
                  "description": "Required when type='attribute'."
                },
                "pattern": {
                  "type": "string",
                  "description": "Regex for type='text' or type='attribute'."
                },
                "min_count": {
                  "type": "integer",
                  "minimum": 0,
                  "description": "For type='exists' or 'count'."
                },
                "max_count": {
                  "type": "integer",
                  "minimum": 0,
                  "description": "For type='count'."
                }
              },
              "required": [
                "type"
              ],
              "additionalProperties": false,
              "allOf": [
                {
                  "if": {
                    "properties": {
                      "type": {
                        "const": "attribute"
                      }
                    }
                  },
                  "then": {
                    "required": [
                      "attribute",
                      "pattern"
                    ]
                  }
                },
                {
                  "if": {
                    "properties": {
                      "type": {
                        "const": "text"
                      }
                    }
                  },
                  "then": {
                    "required": [
                      "pattern"
                    ]
                  }
                },
                {
                  "if": {
                    "properties": {
                      "type": {
                        "const": "exists"
                      }
                    }
                  },
                  "then": {
                    "properties": {
                      "min_count": {
                        "type": "integer",
                        "minimum": 1
                      }
                    }
                  }
                },
                {
                  "if": {
                    "properties": {
                      "type": {
                        "const": "count"
                      }
                    }
                  },
                  "then": {
                    "required": [
                      "min_count"
                    ]
                  }
                }
              ]
            }
          }
        }
      },
      "additionalProperties": false,
      "required": [
        "site"
      ]
    },
    "execution_plan": {
      "title": "CROWler Source Crawling Execution Plan",
      "description": "This is the execution plan for the crawling of the source. It is the plan that the CROWler will use to crawl the source.",
      "type": "array",
      "items": {
        "type": "object",
        "properties": {
          "label": {
            "title": "CROWler Execution Plan Label",
            "description": "This is the label for the execution plan. It is the label that the CROWler will use to identify the execution plan's step.",
            "type": "string"
          },
          "conditions": {
            "title": "CROWler Execution Plan Conditions",
            "description": "This is the conditions for the execution plan. These are the conditions that have to be met to trigger the Execution plan action (aka apply rulesets etc.).",
            "type": "object",
            "properties": {
              "url_patterns": {
                "type": "array",
                "items": {
                  "type": "string"
                }
              }
            },
            "additionalProperties": false,
            "required": [
              "url_patterns"
            ]
          },
          "rulesets": {
            "title": "CROWler Execution Plan Rulesets to apply for this Source",
            "description": "This is the list of rulesets that the CROWler will use to apply for the source.",
            "type": "array",
            "items": {
              "type": "string"
            }
          },
          "rule_groups": {
            "title": "CROWler Execution Plan Rule Groups to apply for this Source",
            "description": "This is the list of rule groups that the CROWler will use to apply for the source. You can use this to list specific rule groups that the CROWler will have to apply for the source.",
            "type": "array",
            "items": {
              "type": "string"
            }
          },
          "rules": {
            "title": "CROWler Execution Plan Rules to apply for this Source",
            "description": "This is the list of rules that the CROWler will use to apply for the source. You can use this to list specific rules that the CROWler will have to apply for the source.",
            "type": "array",
            "items": {
              "type": "string"
            }
          },
          "additional_conditions": {
            "title": "CROWler Execution Plan Additional Conditions",
            "description": "This is the additional conditions for the execution plan. It supports custom tags, but those have to be supported by the CROWler code otherwise they'll be ignored.",
            "type": "object",
            "additionalProperties": true
          }
        },
        "additionalProperties": false,
        "required": [
          "label",
          "conditions"
        ],
        "anyOf": [
          {
            "required": [
              "rulesets"
            ]
          },
          {
            "required": [
              "rule_groups"
            ]
          },
          {
            "required": [
              "rules"
            ]
          }
        ]
      }
    },
    "custom": {
      "title": "CROWler Source Custom Configuration",
      "description": "This is the custom configuration for the source. You can use this to add custom configurations for the source.",
      "type": "object",
      "additionalProperties": true,
      "examples": [
        {
          "custom": {
            "crawler": {
              "max_depth": 5,
              "max_pages": 1000
            }
          }
        }
      ]
    },
    "meta_data": {
      "title": "CROWler Source MetaData Configuration",
      "description": "This is a generic container of structured data that a user wants to be stored with the source and copied in every structured object generated by the CROWler. For instance we can put in here our own IDs for the source, or any other structured data that we want to be stored with every object the CROWler generates out of using/crawling this Source.",
      "type": "object",
      "properties": {},
      "additionalProperties": true
    }
  },
  "additionalProperties": false,
  "required": [
    "format_version",
    "source_name",
    "crawling_config"
  ]
}
